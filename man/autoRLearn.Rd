% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/autoRLearn.R
\name{autoRLearn}
\alias{autoRLearn}
\title{Run smartML function for automatic Supervised Machine Learning.}
\usage{
autoRLearn(maxTime, directory, testDirectory, classCol = "class",
  metric = "acc", vRatio = 0.3, preProcessF = c("standardize", "zv"),
  featuresToPreProcess = c(), nComp = NA, nModels = 5, option = 2,
  featureTypes = c(), interp = FALSE, missingOpr = FALSE,
  balance = FALSE)
}
\arguments{
\item{maxTime}{Float numeric of the maximum time budget for reading dataset, preprocessing, calculating meta-features, Algorithm Selection & hyper-parameter tuning process only in minutes(Excluding Model Interpretability) - This is applicable in case of Option = 2 only.}

\item{directory}{String Character of the training dataset directory (SmartML accepts file formats arff/(csv with columns headers) ).}

\item{testDirectory}{String Character of the testing dataset directory (SmartML accepts file formats arff/(csv with columns headers) ).}

\item{classCol}{String Character of the name of the class label column in the dataset (default = 'class').}

\item{metric}{Metric of string character to be used in evaluation:
\itemize{
\item "acc" - Accuracy,
\item "avg-fscore" - Average of F-Score of each label,
\item "avg-recall" - Average of Recall of each label,
\item "avg-precision" - Average of Precision of each label,
\item "fscore" - Micro-Average of F-Score of each label,
\item "recall" - Micro-Average of Recall of each label,
\item "precision" - Micro-Average of Precision of each label.
}}

\item{vRatio}{Float numeric of the validation set ratio that should be splitted out of the training set for the evaluation process (default = 0.1 --> 10\%).}

\item{preProcessF}{vector of string Character containing the name of the preprocessing algorithms (default = c('standardize', 'zv') --> no preprocessing):
\itemize{
\item "boxcox" - apply a Boxâ€“Cox transform and values must be non-zero and positive in all features,
\item "yeo-Johnson" - apply a Yeo-Johnson transform, like a BoxCox, but values can be negative,
\item "zv" - remove attributes with a zero variance (all the same value),
\item "center" - subtract mean from values,
\item "scale" - divide values by standard deviation,
\item "standardize" - perform both centering and scaling,
\item "normalize" - normalize values,
\item "pca" - transform data to the principal components,
\item "ica" - transform data to the independent components.
}}

\item{featuresToPreProcess}{Vector of number of features to perform the feature preprocessing on - In case of empty vector, this means to include all features in the dataset file (default = c()) - This vector should be a subset of \code{selectedFeats}.}

\item{nComp}{Integer numeric of Number of components needed if either "pca" or "ica" feature preprocessors are needed.}

\item{nModels}{Integer numeric representing the number of classifier algorithms that you want to select based on Meta-Learning and start to tune using Bayesian Optimization (default = 5).}

\item{option}{Integer numeric representing either Classifier Algorithm Selection is needed only = 1 or Algorithm selection with its parameter tuning is required = 2 which is the default value.}

\item{featureTypes}{Vector of either 'numerical' or 'categorical' representing the types of features in the dataset (default = c() --> any factor or character features will be considered as categorical otherwise numerical).}

\item{interp}{Boolean representing if model interpretability (Feature Importance and Interaction) is needed or not (default = FALSE) This option will take more time budget if set to 1.}

\item{missingOpr}{Boolean variable represents either use median/mode imputation for instances with missing values (FALSE) or apply imputation using "MICE" library which helps you imputing missing values with plausible data values that are drawn from a distribution specifically designed for each missing datapoint (TRUE).}

\item{balance}{Boolean variable represents if SMOTE class balancing is required or not (default FALSE).}
}
\value{
List of Results
\itemize{
\item "option=1" - Choosen Classifier Algorithms Names \code{clfs} with their parameters configurations \code{params}, Training DataFrame \code{TRData}, Test DataFrame \code{TEData} in case of \code{option=2},
\item "option=2" - Best classifier algorithm name found \code{clfs} with its parameters configuration \code{params}, , Training DataFrame \code{TRData}, Test DataFrame \code{TEData}, model variable \code{model}, predicted values on test set \code{pred}, performance on TestingSet \code{perf}, and Feature Importance \code{interpret$featImp} / Interaction \code{interpret$Interact} plots in case of interpretability \code{interp} = TRUE and chosen model is not knn.
}
}
\description{
Run the smartML main function for automatic classifier algorithm selection, and hyper-parameter tuning.
}
\examples{
\dontrun{
autoRLearn(1, 'sampleDatasets/car/train.arff', \\
'sampleDatasets/car/test.arff', option = 2, preProcessF = 'normalize')

result <- autoRLearn(10, 'sampleDatasets/shuttle/train.arff', 'sampleDatasets/shuttle/test.arff')
}

}
